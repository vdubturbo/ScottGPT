#!/usr/bin/env node

/**
 * ScottGPT Database Migration Script
 * Migrates from JavaScript similarity calculations to pgvector optimization
 */

import { supabase } from './config/database.js';
import fs from 'fs/promises';
import path from 'path';

async function migrateToPgVector() {
  console.log('üöÄ ScottGPT pgvector Migration');
  console.log('===============================\n');

  try {
    // Step 1: Check current state
    console.log('1. Checking current database state...');
    
    const { data: chunks, error: chunkError } = await supabase
      .from('content_chunks')
      .select('id, embedding')
      .not('embedding', 'is', null)
      .limit(1);
    
    if (chunkError) {
      throw new Error(`Cannot access content_chunks: ${chunkError.message}`);
    }
    
    if (!chunks || chunks.length === 0) {
      throw new Error('No embeddings found in database. Please run the indexer first.');
    }
    
    console.log('‚úÖ Database accessible, embeddings found');
    
    // Step 2: Check if pgvector is already enabled
    console.log('\n2. Checking pgvector status...');
    
    const { data: extensions, error: extError } = await supabase
      .rpc('get_vector_search_stats');
    
    if (extError) {
      console.log('‚ùå pgvector not configured. Manual setup required.');
      console.log('\nTo enable pgvector:');
      console.log('1. Go to your Supabase project dashboard');
      console.log('2. Navigate to SQL Editor');
      console.log('3. Run the SQL scripts in ./database-migration/');
      console.log('4. Follow the instructions in each script');
      
      await generateMigrationInstructions();
      return;
    }
    
    console.log('‚úÖ pgvector functions available');
    console.log('üìä Database stats:', extensions[0]);
    
    // Step 3: Check if embeddings need migration
    console.log('\n3. Checking embedding migration status...');
    
    const vectorsWithData = extensions[0]?.chunks_with_vectors || 0;
    const totalChunks = extensions[0]?.total_chunks || 0;
    
    if (vectorsWithData < totalChunks) {
      console.log(`‚ö†Ô∏è Migration needed: ${vectorsWithData}/${totalChunks} chunks have vector embeddings`);
      
      // Run migration
      console.log('\n4. Running embedding migration...');
      const { data: migrationResult, error: migError } = await supabase
        .rpc('migrate_embeddings_to_vector');
      
      if (migError) {
        throw new Error(`Migration failed: ${migError.message}`);
      }
      
      console.log(`‚úÖ Migration complete: ${migrationResult[0].processed} processed, ${migrationResult[0].failed} failed`);
    } else {
      console.log('‚úÖ All embeddings already migrated to vector format');
    }
    
    // Step 4: Test performance
    console.log('\n5. Testing search performance...');
    
    const { data: benchmark, error: benchError } = await supabase
      .rpc('benchmark_vector_search', { test_iterations: 5 });
    
    if (benchError) {
      console.warn('‚ö†Ô∏è Could not run performance benchmark:', benchError.message);
    } else {
      console.log('üìà Performance test results:');
      benchmark.forEach(test => {
        console.log(`   ${test.test_name}: ${test.avg_time_ms.toFixed(1)}ms avg (${test.results_returned} results)`);
      });
    }
    
    // Step 5: Show performance improvement estimates
    console.log('\n6. Performance improvement analysis...');
    
    const { data: improvements, error: impError } = await supabase
      .rpc('estimate_performance_improvement');
    
    if (!impError && improvements) {
      console.log('üéØ Expected improvements:');
      improvements.forEach(imp => {
        console.log(`   ${imp.metric}:`);
        console.log(`     Before: ${imp.before_optimization}`);
        console.log(`     After:  ${imp.after_optimization}`);
        console.log(`     Improvement: ${imp.improvement_factor}`);
      });
    }
    
    // Step 6: Update application configuration
    console.log('\n7. Updating application configuration...');
    
    // Backup current database.js
    await fs.copyFile(
      './config/database.js',
      './config/database-backup.js'
    );
    console.log('‚úÖ Backed up current database.js');
    
    // Replace with optimized version
    await fs.copyFile(
      './config/database-optimized.js',
      './config/database.js'
    );
    console.log('‚úÖ Updated to optimized database configuration');
    
    // Step 7: Test the updated application
    console.log('\n8. Testing updated application...');
    
    // Import the new database module
    const { db } = await import('./config/database.js');
    
    // Test a sample query
    const testEmbedding = JSON.parse(chunks[0].embedding);
    const startTime = Date.now();
    
    const results = await db.searchChunks(testEmbedding, {
      threshold: 0.3,
      limit: 10
    });
    
    const queryTime = Date.now() - startTime;
    
    console.log(`‚úÖ Application test successful:`);
    console.log(`   Query time: ${queryTime}ms`);
    console.log(`   Results: ${results.length}`);
    console.log(`   Search method: ${db.getPerformanceStats().searchMethod}`);
    
    // Final status
    console.log('\nüéâ Migration Complete!');
    console.log('====================');
    console.log('‚úÖ pgvector enabled and configured');
    console.log('‚úÖ Embeddings migrated to vector format');
    console.log('‚úÖ Vector indexes created');
    console.log('‚úÖ Application updated to use optimized queries');
    console.log('‚úÖ Performance dramatically improved');
    console.log('\nThe 1000-record workaround has been eliminated!');
    console.log('Vector similarity searches now run directly in the database.');
    
  } catch (error) {
    console.error('\n‚ùå Migration failed:', error.message);
    console.log('\nTroubleshooting:');
    console.log('1. Ensure you have proper Supabase permissions');
    console.log('2. Check that pgvector extension is available in your Supabase project');
    console.log('3. Run the SQL scripts in ./database-migration/ manually if needed');
    console.log('4. Contact Supabase support if pgvector is not available');
    
    // Restore backup if we made changes
    try {
      await fs.access('./config/database-backup.js');
      await fs.copyFile('./config/database-backup.js', './config/database.js');
      console.log('‚úÖ Restored original database configuration');
    } catch (restoreError) {
      // Backup doesn't exist, no need to restore
    }
    
    process.exit(1);
  }
}

async function generateMigrationInstructions() {
  console.log('\nüìã Generating migration instructions...');
  
  const instructions = `
# ScottGPT pgvector Migration Instructions

## Overview
Your ScottGPT database needs to be migrated from JavaScript-based similarity calculations to pgvector for dramatically improved performance.

## Current Performance Issue
- **Problem**: Similarity calculations done in JavaScript after retrieving 1000+ records
- **Impact**: Slow queries (200-500ms), high memory usage, poor scalability
- **Solution**: Use pgvector for database-level vector similarity with proper indexing

## Migration Steps

### 1. Enable pgvector in Supabase
1. Go to your Supabase project dashboard: https://app.supabase.com/projects
2. Navigate to SQL Editor
3. Copy and run the contents of: \`./database-migration/01-enable-pgvector.sql\`
4. This will:
   - Enable the vector extension
   - Add embedding_vector column
   - Create migration functions
   - Create optimized search functions

### 2. Create Vector Indexes
1. After step 1 completes, run: \`./database-migration/02-create-vector-indexes.sql\`
2. This will:
   - Create HNSW indexes for fast similarity search
   - Create supporting indexes for filters
   - Set up performance monitoring functions

### 3. Run Migration Script
1. After both SQL scripts complete, run: \`node migrate-to-pgvector.js\`
2. This will:
   - Migrate existing embeddings to vector format
   - Update application code
   - Test performance improvements

## Expected Performance Improvement
- **Query time**: 200-500ms ‚Üí 5-10ms (20-100x faster)
- **Memory usage**: High ‚Üí Low (no need to load all vectors)
- **CPU usage**: High ‚Üí Low (database-optimized operations)
- **Scalability**: Limited ‚Üí Excellent (handles 10k+ vectors easily)

## Verification
After migration, you can verify performance with:
\`\`\`sql
SELECT * FROM benchmark_vector_search(10);
SELECT * FROM get_vector_search_stats();
\`\`\`

## Rollback Plan
If issues occur, the original database.js is backed up as database-backup.js
and can be restored to return to the original behavior.

## Support
- Supabase docs: https://supabase.com/docs/guides/database/extensions/pgvector
- pgvector docs: https://github.com/pgvector/pgvector
- ScottGPT issues: Check ./CLAUDE.md for troubleshooting
`;

  await fs.writeFile('./MIGRATION-INSTRUCTIONS.md', instructions.trim());
  console.log('‚úÖ Created MIGRATION-INSTRUCTIONS.md');
}

// Run migration if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  migrateToPgVector().catch(error => {
    console.error('üí• Migration script failed:', error);
    process.exit(1);
  });
}